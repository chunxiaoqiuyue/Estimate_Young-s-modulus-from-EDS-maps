{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from PIL import Image,ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.preprocessing.image import load_img,img_to_array,array_to_img,ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.models import Sequential,Model, load_model\n",
    "\n",
    "from keras.layers import Input, Activation, Flatten, Dense, Flatten,Conv2D, Dropout, MaxPool2D, GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "from keras.callbacks.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load EDS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_EDS_0221=np.load('22092_EDS_Dataset4.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Young's modulus Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_22092_0221=[20.37,20.94,22.42,25.39,15.20,17.30,17.20,19.26,15.88,23.10]\n",
    "Y_EDS_0221=[]\n",
    "for i in range(10):\n",
    "    Y_EDS_0221.extend([E_22092_0221[i]]*80)\n",
    "    \n",
    "Y_EDS_0221=pd.DataFrame(Y_EDS_0221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_EDS_0221,Y_EDS_0221=shuffle(X_EDS_0221,Y_EDS_0221)\n",
    "X_EDS_train,X_EDS_test,Y_EDS_train,Y_EDS_test=train_test_split(X_EDS_0221,Y_EDS_0221,test_size=0.25,random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_mod_3(lr = 0.00001):\n",
    "    model=Sequential()\n",
    "    \n",
    "    model.add(Conv2D(input_shape=(112,112,9),filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dense(units=100,activation=\"relu\"))\n",
    "    model.add(Dense(units=100,activation=\"relu\"))\n",
    "    model.add(Dense(units=100,activation=\"relu\"))\n",
    "    model.add(Dense(units=1, activation=\"linear\"))\n",
    "    \n",
    "    \n",
    "    sgd = optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(optimizer=sgd,loss=\"mean_absolute_percentage_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_7 = vgg16_mod_3(lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_eds_10292021_lr_7.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 98.1414 - val_loss: 97.5472\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 97.54716, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 2/200\n",
      "600/600 [==============================] - 54s 89ms/step - loss: 96.9222 - val_loss: 96.2962\n",
      "\n",
      "Epoch 00002: val_loss improved from 97.54716 to 96.29616, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 3/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 95.7458 - val_loss: 95.2208\n",
      "\n",
      "Epoch 00003: val_loss improved from 96.29616 to 95.22081, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 4/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 94.7002 - val_loss: 94.1920\n",
      "\n",
      "Epoch 00004: val_loss improved from 95.22081 to 94.19196, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 5/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 93.6504 - val_loss: 93.1141\n",
      "\n",
      "Epoch 00005: val_loss improved from 94.19196 to 93.11412, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 6/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 92.5015 - val_loss: 91.8863\n",
      "\n",
      "Epoch 00006: val_loss improved from 93.11412 to 91.88629, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 7/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 91.1578 - val_loss: 90.4246\n",
      "\n",
      "Epoch 00007: val_loss improved from 91.88629 to 90.42463, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 8/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 89.5638 - val_loss: 88.7146\n",
      "\n",
      "Epoch 00008: val_loss improved from 90.42463 to 88.71464, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 9/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 87.7347 - val_loss: 86.7532\n",
      "\n",
      "Epoch 00009: val_loss improved from 88.71464 to 86.75324, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 10/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 85.5945 - val_loss: 84.4281\n",
      "\n",
      "Epoch 00010: val_loss improved from 86.75324 to 84.42814, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 11/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 83.0068 - val_loss: 81.5714\n",
      "\n",
      "Epoch 00011: val_loss improved from 84.42814 to 81.57138, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 12/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 79.7660 - val_loss: 77.8864\n",
      "\n",
      "Epoch 00012: val_loss improved from 81.57138 to 77.88641, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 13/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 75.5001 - val_loss: 72.9289\n",
      "\n",
      "Epoch 00013: val_loss improved from 77.88641 to 72.92891, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 14/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 69.6480 - val_loss: 66.0344\n",
      "\n",
      "Epoch 00014: val_loss improved from 72.92891 to 66.03440, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 15/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 61.3685 - val_loss: 56.0094\n",
      "\n",
      "Epoch 00015: val_loss improved from 66.03440 to 56.00941, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 16/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 48.8464 - val_loss: 40.2463\n",
      "\n",
      "Epoch 00016: val_loss improved from 56.00941 to 40.24630, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 17/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 28.3701 - val_loss: 16.4617\n",
      "\n",
      "Epoch 00017: val_loss improved from 40.24630 to 16.46169, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 18/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 12.8867 - val_loss: 12.5378\n",
      "\n",
      "Epoch 00018: val_loss improved from 16.46169 to 12.53777, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 19/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 12.4580 - val_loss: 12.5492\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 12.53777\n",
      "Epoch 20/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 12.3670 - val_loss: 12.5967\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 12.53777\n",
      "Epoch 21/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 12.3511 - val_loss: 12.4264\n",
      "\n",
      "Epoch 00021: val_loss improved from 12.53777 to 12.42644, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 22/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 12.2936 - val_loss: 12.3647\n",
      "\n",
      "Epoch 00022: val_loss improved from 12.42644 to 12.36471, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 23/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 12.2399 - val_loss: 12.3810\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 12.36471\n",
      "Epoch 24/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 12.1768 - val_loss: 12.3436\n",
      "\n",
      "Epoch 00024: val_loss improved from 12.36471 to 12.34361, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 25/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 12.1326 - val_loss: 12.3533\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 12.34361\n",
      "Epoch 26/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 12.0925 - val_loss: 12.2732\n",
      "\n",
      "Epoch 00026: val_loss improved from 12.34361 to 12.27318, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 27/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 12.0489 - val_loss: 12.2601\n",
      "\n",
      "Epoch 00027: val_loss improved from 12.27318 to 12.26009, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 28/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 12.0107 - val_loss: 12.1766\n",
      "\n",
      "Epoch 00028: val_loss improved from 12.26009 to 12.17656, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 29/200\n",
      "600/600 [==============================] - 54s 91ms/step - loss: 11.9552 - val_loss: 12.1389\n",
      "\n",
      "Epoch 00029: val_loss improved from 12.17656 to 12.13886, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 30/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 11.9218 - val_loss: 12.0847\n",
      "\n",
      "Epoch 00030: val_loss improved from 12.13886 to 12.08473, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 31/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 11.8720 - val_loss: 12.0674\n",
      "\n",
      "Epoch 00031: val_loss improved from 12.08473 to 12.06740, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 32/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 11.8685 - val_loss: 12.0473\n",
      "\n",
      "Epoch 00032: val_loss improved from 12.06740 to 12.04732, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 33/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 11.8004 - val_loss: 11.9667\n",
      "\n",
      "Epoch 00033: val_loss improved from 12.04732 to 11.96673, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 34/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 11.7621 - val_loss: 11.9582\n",
      "\n",
      "Epoch 00034: val_loss improved from 11.96673 to 11.95818, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 35/200\n",
      "600/600 [==============================] - 61s 102ms/step - loss: 11.7742 - val_loss: 11.8834\n",
      "\n",
      "Epoch 00035: val_loss improved from 11.95818 to 11.88343, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 36/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 11.6992 - val_loss: 11.8527\n",
      "\n",
      "Epoch 00036: val_loss improved from 11.88343 to 11.85269, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 37/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 11.6430 - val_loss: 11.8804\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 11.85269\n",
      "Epoch 38/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 11.6040 - val_loss: 11.7903\n",
      "\n",
      "Epoch 00038: val_loss improved from 11.85269 to 11.79029, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 39/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 11.5839 - val_loss: 11.7968\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 11.79029\n",
      "Epoch 40/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 11.5357 - val_loss: 11.7443\n",
      "\n",
      "Epoch 00040: val_loss improved from 11.79029 to 11.74428, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 41/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 11.4797 - val_loss: 11.7411\n",
      "\n",
      "Epoch 00041: val_loss improved from 11.74428 to 11.74112, saving model to vgg16_eds_10292021_lr_7.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 11.4478 - val_loss: 11.6742\n",
      "\n",
      "Epoch 00042: val_loss improved from 11.74112 to 11.67415, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 43/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 11.4277 - val_loss: 11.6232\n",
      "\n",
      "Epoch 00043: val_loss improved from 11.67415 to 11.62321, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 44/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 11.3802 - val_loss: 11.5936\n",
      "\n",
      "Epoch 00044: val_loss improved from 11.62321 to 11.59365, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 45/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 11.3489 - val_loss: 11.6065\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 11.59365\n",
      "Epoch 46/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 11.2945 - val_loss: 11.5492\n",
      "\n",
      "Epoch 00046: val_loss improved from 11.59365 to 11.54922, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 47/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 11.2671 - val_loss: 11.5132\n",
      "\n",
      "Epoch 00047: val_loss improved from 11.54922 to 11.51320, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 48/200\n",
      "600/600 [==============================] - 60s 100ms/step - loss: 11.2373 - val_loss: 11.4879\n",
      "\n",
      "Epoch 00048: val_loss improved from 11.51320 to 11.48792, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 49/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 11.1925 - val_loss: 11.4588\n",
      "\n",
      "Epoch 00049: val_loss improved from 11.48792 to 11.45884, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 50/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 11.1488 - val_loss: 11.4869\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 11.45884\n",
      "Epoch 51/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 11.1314 - val_loss: 11.3943\n",
      "\n",
      "Epoch 00051: val_loss improved from 11.45884 to 11.39432, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 52/200\n",
      "600/600 [==============================] - 54s 89ms/step - loss: 11.1035 - val_loss: 11.4284\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 11.39432\n",
      "Epoch 53/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 11.0427 - val_loss: 11.3457\n",
      "\n",
      "Epoch 00053: val_loss improved from 11.39432 to 11.34567, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 54/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 11.0495 - val_loss: 11.3243\n",
      "\n",
      "Epoch 00054: val_loss improved from 11.34567 to 11.32433, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 55/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 10.9946 - val_loss: 11.3239\n",
      "\n",
      "Epoch 00055: val_loss improved from 11.32433 to 11.32387, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 56/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 10.9697 - val_loss: 11.3010\n",
      "\n",
      "Epoch 00056: val_loss improved from 11.32387 to 11.30097, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 57/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 10.9383 - val_loss: 11.2441\n",
      "\n",
      "Epoch 00057: val_loss improved from 11.30097 to 11.24409, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 58/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 10.9180 - val_loss: 11.2302\n",
      "\n",
      "Epoch 00058: val_loss improved from 11.24409 to 11.23021, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 59/200\n",
      "600/600 [==============================] - 54s 89ms/step - loss: 10.8818 - val_loss: 11.2478\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 11.23021\n",
      "Epoch 60/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 10.9139 - val_loss: 11.1734\n",
      "\n",
      "Epoch 00060: val_loss improved from 11.23021 to 11.17336, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 61/200\n",
      "600/600 [==============================] - 61s 102ms/step - loss: 10.8242 - val_loss: 11.1758\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 11.17336\n",
      "Epoch 62/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 10.8005 - val_loss: 11.1203\n",
      "\n",
      "Epoch 00062: val_loss improved from 11.17336 to 11.12028, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 63/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 10.7667 - val_loss: 11.0960\n",
      "\n",
      "Epoch 00063: val_loss improved from 11.12028 to 11.09601, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 64/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 10.7242 - val_loss: 11.0890\n",
      "\n",
      "Epoch 00064: val_loss improved from 11.09601 to 11.08895, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 65/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 10.6944 - val_loss: 11.0535\n",
      "\n",
      "Epoch 00065: val_loss improved from 11.08895 to 11.05346, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 66/200\n",
      "600/600 [==============================] - 56s 94ms/step - loss: 10.6738 - val_loss: 11.0427\n",
      "\n",
      "Epoch 00066: val_loss improved from 11.05346 to 11.04268, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 67/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 10.6636 - val_loss: 11.0133\n",
      "\n",
      "Epoch 00067: val_loss improved from 11.04268 to 11.01330, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 68/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 10.6165 - val_loss: 10.9822\n",
      "\n",
      "Epoch 00068: val_loss improved from 11.01330 to 10.98221, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 69/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 10.5851 - val_loss: 10.9555\n",
      "\n",
      "Epoch 00069: val_loss improved from 10.98221 to 10.95552, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 70/200\n",
      "600/600 [==============================] - 54s 89ms/step - loss: 10.5526 - val_loss: 10.9366\n",
      "\n",
      "Epoch 00070: val_loss improved from 10.95552 to 10.93657, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 71/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 10.5236 - val_loss: 10.9191\n",
      "\n",
      "Epoch 00071: val_loss improved from 10.93657 to 10.91914, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 72/200\n",
      "600/600 [==============================] - 57s 94ms/step - loss: 10.5033 - val_loss: 10.8977\n",
      "\n",
      "Epoch 00072: val_loss improved from 10.91914 to 10.89772, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 73/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 10.4959 - val_loss: 10.8648\n",
      "\n",
      "Epoch 00073: val_loss improved from 10.89772 to 10.86475, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 74/200\n",
      "600/600 [==============================] - 59s 99ms/step - loss: 10.4764 - val_loss: 10.8375\n",
      "\n",
      "Epoch 00074: val_loss improved from 10.86475 to 10.83754, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 75/200\n",
      "600/600 [==============================] - 54s 91ms/step - loss: 10.4423 - val_loss: 10.8144\n",
      "\n",
      "Epoch 00075: val_loss improved from 10.83754 to 10.81440, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 76/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 10.4076 - val_loss: 10.7951\n",
      "\n",
      "Epoch 00076: val_loss improved from 10.81440 to 10.79506, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 77/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 10.3442 - val_loss: 10.7795\n",
      "\n",
      "Epoch 00077: val_loss improved from 10.79506 to 10.77951, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 78/200\n",
      "600/600 [==============================] - 54s 89ms/step - loss: 10.3649 - val_loss: 10.7536\n",
      "\n",
      "Epoch 00078: val_loss improved from 10.77951 to 10.75356, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 79/200\n",
      "600/600 [==============================] - 54s 89ms/step - loss: 10.2960 - val_loss: 10.7238\n",
      "\n",
      "Epoch 00079: val_loss improved from 10.75356 to 10.72381, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 80/200\n",
      "600/600 [==============================] - 54s 89ms/step - loss: 10.3068 - val_loss: 10.7066\n",
      "\n",
      "Epoch 00080: val_loss improved from 10.72381 to 10.70656, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 81/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 10.2657 - val_loss: 10.6800\n",
      "\n",
      "Epoch 00081: val_loss improved from 10.70656 to 10.68002, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 82/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 10.2295 - val_loss: 10.6582\n",
      "\n",
      "Epoch 00082: val_loss improved from 10.68002 to 10.65825, saving model to vgg16_eds_10292021_lr_7.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 10.2400 - val_loss: 10.6525\n",
      "\n",
      "Epoch 00083: val_loss improved from 10.65825 to 10.65255, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 84/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 10.1849 - val_loss: 10.6158\n",
      "\n",
      "Epoch 00084: val_loss improved from 10.65255 to 10.61582, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 85/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 10.1811 - val_loss: 10.6018\n",
      "\n",
      "Epoch 00085: val_loss improved from 10.61582 to 10.60180, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 86/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 10.1279 - val_loss: 10.5970\n",
      "\n",
      "Epoch 00086: val_loss improved from 10.60180 to 10.59702, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 87/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 10.1757 - val_loss: 10.5885\n",
      "\n",
      "Epoch 00087: val_loss improved from 10.59702 to 10.58848, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 88/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 10.0857 - val_loss: 10.5309\n",
      "\n",
      "Epoch 00088: val_loss improved from 10.58848 to 10.53090, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 89/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 10.0765 - val_loss: 10.5078\n",
      "\n",
      "Epoch 00089: val_loss improved from 10.53090 to 10.50775, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 90/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 10.0805 - val_loss: 10.4867\n",
      "\n",
      "Epoch 00090: val_loss improved from 10.50775 to 10.48671, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 91/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 10.0234 - val_loss: 10.4714\n",
      "\n",
      "Epoch 00091: val_loss improved from 10.48671 to 10.47135, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 92/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 9.9931 - val_loss: 10.4571\n",
      "\n",
      "Epoch 00092: val_loss improved from 10.47135 to 10.45707, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 93/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 10.0032 - val_loss: 10.4276\n",
      "\n",
      "Epoch 00093: val_loss improved from 10.45707 to 10.42761, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 94/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 9.9604 - val_loss: 10.4278\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 10.42761\n",
      "Epoch 95/200\n",
      "600/600 [==============================] - 54s 91ms/step - loss: 9.9308 - val_loss: 10.3886\n",
      "\n",
      "Epoch 00095: val_loss improved from 10.42761 to 10.38863, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 96/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 9.9290 - val_loss: 10.3629\n",
      "\n",
      "Epoch 00096: val_loss improved from 10.38863 to 10.36287, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 97/200\n",
      "600/600 [==============================] - 54s 91ms/step - loss: 9.9104 - val_loss: 10.3513\n",
      "\n",
      "Epoch 00097: val_loss improved from 10.36287 to 10.35128, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 98/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.8728 - val_loss: 10.3235\n",
      "\n",
      "Epoch 00098: val_loss improved from 10.35128 to 10.32350, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 99/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 9.8976 - val_loss: 10.3325\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 10.32350\n",
      "Epoch 100/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.7839 - val_loss: 10.3075\n",
      "\n",
      "Epoch 00100: val_loss improved from 10.32350 to 10.30748, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 101/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 9.8413 - val_loss: 10.2588\n",
      "\n",
      "Epoch 00101: val_loss improved from 10.30748 to 10.25884, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 102/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.7882 - val_loss: 10.2434\n",
      "\n",
      "Epoch 00102: val_loss improved from 10.25884 to 10.24341, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 103/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.7677 - val_loss: 10.2209\n",
      "\n",
      "Epoch 00103: val_loss improved from 10.24341 to 10.22087, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 104/200\n",
      "600/600 [==============================] - 58s 97ms/step - loss: 9.7505 - val_loss: 10.2009\n",
      "\n",
      "Epoch 00104: val_loss improved from 10.22087 to 10.20086, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 105/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 9.7322 - val_loss: 10.1802\n",
      "\n",
      "Epoch 00105: val_loss improved from 10.20086 to 10.18023, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 106/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.7212 - val_loss: 10.1585\n",
      "\n",
      "Epoch 00106: val_loss improved from 10.18023 to 10.15851, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 107/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 9.7280 - val_loss: 10.1458\n",
      "\n",
      "Epoch 00107: val_loss improved from 10.15851 to 10.14577, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 108/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 9.6813 - val_loss: 10.1412\n",
      "\n",
      "Epoch 00108: val_loss improved from 10.14577 to 10.14122, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 109/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 9.6599 - val_loss: 10.0990\n",
      "\n",
      "Epoch 00109: val_loss improved from 10.14122 to 10.09896, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 110/200\n",
      "600/600 [==============================] - 56s 94ms/step - loss: 9.6206 - val_loss: 10.1590\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 10.09896\n",
      "Epoch 111/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 9.6254 - val_loss: 10.0704\n",
      "\n",
      "Epoch 00111: val_loss improved from 10.09896 to 10.07038, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 112/200\n",
      "600/600 [==============================] - 54s 91ms/step - loss: 9.6117 - val_loss: 10.0445\n",
      "\n",
      "Epoch 00112: val_loss improved from 10.07038 to 10.04449, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 113/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.5894 - val_loss: 10.0264\n",
      "\n",
      "Epoch 00113: val_loss improved from 10.04449 to 10.02645, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 114/200\n",
      "600/600 [==============================] - 60s 99ms/step - loss: 9.5642 - val_loss: 10.0069\n",
      "\n",
      "Epoch 00114: val_loss improved from 10.02645 to 10.00691, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 115/200\n",
      "600/600 [==============================] - 54s 91ms/step - loss: 9.5466 - val_loss: 10.0037\n",
      "\n",
      "Epoch 00115: val_loss improved from 10.00691 to 10.00366, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 116/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.5150 - val_loss: 9.9612\n",
      "\n",
      "Epoch 00116: val_loss improved from 10.00366 to 9.96120, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 117/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.5014 - val_loss: 9.9422\n",
      "\n",
      "Epoch 00117: val_loss improved from 9.96120 to 9.94220, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 118/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.5013 - val_loss: 9.9825\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 9.94220\n",
      "Epoch 119/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 9.4611 - val_loss: 9.9095\n",
      "\n",
      "Epoch 00119: val_loss improved from 9.94220 to 9.90953, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 120/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.4334 - val_loss: 9.8968\n",
      "\n",
      "Epoch 00120: val_loss improved from 9.90953 to 9.89682, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 121/200\n",
      "600/600 [==============================] - 54s 91ms/step - loss: 9.4148 - val_loss: 9.8808\n",
      "\n",
      "Epoch 00121: val_loss improved from 9.89682 to 9.88079, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 122/200\n",
      "600/600 [==============================] - 59s 99ms/step - loss: 9.3998 - val_loss: 9.9182\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 9.88079\n",
      "Epoch 123/200\n",
      "600/600 [==============================] - 56s 94ms/step - loss: 9.4098 - val_loss: 9.8424\n",
      "\n",
      "Epoch 00123: val_loss improved from 9.88079 to 9.84240, saving model to vgg16_eds_10292021_lr_7.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "600/600 [==============================] - 59s 99ms/step - loss: 9.3625 - val_loss: 9.8608\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 9.84240\n",
      "Epoch 125/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 9.4200 - val_loss: 9.8411\n",
      "\n",
      "Epoch 00125: val_loss improved from 9.84240 to 9.84107, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 126/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 9.3459 - val_loss: 9.7939\n",
      "\n",
      "Epoch 00126: val_loss improved from 9.84107 to 9.79390, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 127/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.3091 - val_loss: 9.7778\n",
      "\n",
      "Epoch 00127: val_loss improved from 9.79390 to 9.77776, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 128/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 9.3250 - val_loss: 9.8171\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 9.77776\n",
      "Epoch 129/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 9.3040 - val_loss: 9.7659\n",
      "\n",
      "Epoch 00129: val_loss improved from 9.77776 to 9.76591, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 130/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.2930 - val_loss: 9.7999\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 9.76591\n",
      "Epoch 131/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.2700 - val_loss: 9.7758\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 9.76591\n",
      "Epoch 132/200\n",
      "600/600 [==============================] - 53s 89ms/step - loss: 9.2361 - val_loss: 9.7184\n",
      "\n",
      "Epoch 00132: val_loss improved from 9.76591 to 9.71837, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 133/200\n",
      "600/600 [==============================] - 54s 89ms/step - loss: 9.2263 - val_loss: 9.7176\n",
      "\n",
      "Epoch 00133: val_loss improved from 9.71837 to 9.71763, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 134/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 9.2008 - val_loss: 9.7111\n",
      "\n",
      "Epoch 00134: val_loss improved from 9.71763 to 9.71110, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 135/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.1693 - val_loss: 9.6795\n",
      "\n",
      "Epoch 00135: val_loss improved from 9.71110 to 9.67955, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 136/200\n",
      "600/600 [==============================] - 53s 88ms/step - loss: 9.1705 - val_loss: 9.6494\n",
      "\n",
      "Epoch 00136: val_loss improved from 9.67955 to 9.64935, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 137/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 9.1329 - val_loss: 9.6795\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 9.64935\n",
      "Epoch 138/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 9.1555 - val_loss: 9.6469\n",
      "\n",
      "Epoch 00138: val_loss improved from 9.64935 to 9.64690, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 139/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 9.1315 - val_loss: 9.6092\n",
      "\n",
      "Epoch 00139: val_loss improved from 9.64690 to 9.60916, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 140/200\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 9.1059 - val_loss: 9.6672\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 9.60916\n",
      "Epoch 141/200\n",
      "600/600 [==============================] - 10857s 18s/step - loss: 9.0977 - val_loss: 9.6002\n",
      "\n",
      "Epoch 00141: val_loss improved from 9.60916 to 9.60023, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 142/200\n",
      "600/600 [==============================] - 42856s 71s/step - loss: 9.0920 - val_loss: 9.5725\n",
      "\n",
      "Epoch 00142: val_loss improved from 9.60023 to 9.57249, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 143/200\n",
      "600/600 [==============================] - 72s 120ms/step - loss: 9.0472 - val_loss: 9.5615\n",
      "\n",
      "Epoch 00143: val_loss improved from 9.57249 to 9.56146, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 144/200\n",
      "600/600 [==============================] - 64s 107ms/step - loss: 9.0387 - val_loss: 9.5550\n",
      "\n",
      "Epoch 00144: val_loss improved from 9.56146 to 9.55499, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 145/200\n",
      "600/600 [==============================] - 62s 104ms/step - loss: 9.0725 - val_loss: 9.5376\n",
      "\n",
      "Epoch 00145: val_loss improved from 9.55499 to 9.53757, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 146/200\n",
      "600/600 [==============================] - 63s 104ms/step - loss: 9.0123 - val_loss: 9.5251\n",
      "\n",
      "Epoch 00146: val_loss improved from 9.53757 to 9.52513, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 147/200\n",
      "600/600 [==============================] - 65s 109ms/step - loss: 8.9901 - val_loss: 9.5114\n",
      "\n",
      "Epoch 00147: val_loss improved from 9.52513 to 9.51143, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 148/200\n",
      "600/600 [==============================] - 62s 104ms/step - loss: 8.9954 - val_loss: 9.5004\n",
      "\n",
      "Epoch 00148: val_loss improved from 9.51143 to 9.50042, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 149/200\n",
      "600/600 [==============================] - 66s 110ms/step - loss: 8.9581 - val_loss: 9.4872\n",
      "\n",
      "Epoch 00149: val_loss improved from 9.50042 to 9.48723, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 150/200\n",
      "600/600 [==============================] - 61s 102ms/step - loss: 8.9619 - val_loss: 9.4816\n",
      "\n",
      "Epoch 00150: val_loss improved from 9.48723 to 9.48160, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 151/200\n",
      "600/600 [==============================] - 63s 105ms/step - loss: 8.9337 - val_loss: 9.4711\n",
      "\n",
      "Epoch 00151: val_loss improved from 9.48160 to 9.47111, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 152/200\n",
      "600/600 [==============================] - 62s 104ms/step - loss: 8.9128 - val_loss: 9.4876\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 9.47111\n",
      "Epoch 153/200\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 8.9343 - val_loss: 9.4418\n",
      "\n",
      "Epoch 00153: val_loss improved from 9.47111 to 9.44176, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 154/200\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 8.9284 - val_loss: 9.4680\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 9.44176\n",
      "Epoch 155/200\n",
      "600/600 [==============================] - 61s 102ms/step - loss: 8.8979 - val_loss: 9.4306\n",
      "\n",
      "Epoch 00155: val_loss improved from 9.44176 to 9.43057, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 156/200\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 8.9007 - val_loss: 9.4370\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 9.43057\n",
      "Epoch 157/200\n",
      "600/600 [==============================] - 61s 102ms/step - loss: 8.8448 - val_loss: 9.3951\n",
      "\n",
      "Epoch 00157: val_loss improved from 9.43057 to 9.39508, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 158/200\n",
      "600/600 [==============================] - 61s 102ms/step - loss: 8.8579 - val_loss: 9.3820\n",
      "\n",
      "Epoch 00158: val_loss improved from 9.39508 to 9.38196, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 159/200\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 8.8342 - val_loss: 9.3745\n",
      "\n",
      "Epoch 00159: val_loss improved from 9.38196 to 9.37449, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 160/200\n",
      "600/600 [==============================] - 61s 102ms/step - loss: 8.8653 - val_loss: 9.3582\n",
      "\n",
      "Epoch 00160: val_loss improved from 9.37449 to 9.35823, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 161/200\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 8.7918 - val_loss: 9.3971\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 9.35823\n",
      "Epoch 162/200\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 8.8411 - val_loss: 9.3374\n",
      "\n",
      "Epoch 00162: val_loss improved from 9.35823 to 9.33736, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 163/200\n",
      "600/600 [==============================] - 61s 102ms/step - loss: 8.7695 - val_loss: 9.3216\n",
      "\n",
      "Epoch 00163: val_loss improved from 9.33736 to 9.32155, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 164/200\n",
      "600/600 [==============================] - 61s 101ms/step - loss: 8.8105 - val_loss: 9.3215\n",
      "\n",
      "Epoch 00164: val_loss improved from 9.32155 to 9.32147, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 165/200\n",
      "600/600 [==============================] - 63s 105ms/step - loss: 8.8070 - val_loss: 9.3178\n",
      "\n",
      "Epoch 00165: val_loss improved from 9.32147 to 9.31776, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 61s 102ms/step - loss: 8.7877 - val_loss: 9.3022\n",
      "\n",
      "Epoch 00166: val_loss improved from 9.31776 to 9.30224, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 167/200\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 8.7283 - val_loss: 9.2897\n",
      "\n",
      "Epoch 00167: val_loss improved from 9.30224 to 9.28968, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 168/200\n",
      "600/600 [==============================] - 61s 102ms/step - loss: 8.7585 - val_loss: 9.3013\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 9.28968\n",
      "Epoch 169/200\n",
      "600/600 [==============================] - 62s 103ms/step - loss: 8.7341 - val_loss: 9.2549\n",
      "\n",
      "Epoch 00169: val_loss improved from 9.28968 to 9.25489, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 170/200\n",
      "600/600 [==============================] - 60s 101ms/step - loss: 8.7604 - val_loss: 9.2450\n",
      "\n",
      "Epoch 00170: val_loss improved from 9.25489 to 9.24496, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 171/200\n",
      "600/600 [==============================] - 63s 105ms/step - loss: 8.7086 - val_loss: 9.2372\n",
      "\n",
      "Epoch 00171: val_loss improved from 9.24496 to 9.23716, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 172/200\n",
      "600/600 [==============================] - 61s 101ms/step - loss: 8.6831 - val_loss: 9.2281\n",
      "\n",
      "Epoch 00172: val_loss improved from 9.23716 to 9.22814, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 173/200\n",
      "600/600 [==============================] - 76s 127ms/step - loss: 8.6928 - val_loss: 9.2231\n",
      "\n",
      "Epoch 00173: val_loss improved from 9.22814 to 9.22315, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 174/200\n",
      "600/600 [==============================] - 64s 106ms/step - loss: 8.6637 - val_loss: 9.2363\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 9.22315\n",
      "Epoch 175/200\n",
      "600/600 [==============================] - 67s 111ms/step - loss: 8.6747 - val_loss: 9.2030\n",
      "\n",
      "Epoch 00175: val_loss improved from 9.22315 to 9.20296, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 176/200\n",
      "600/600 [==============================] - 66s 110ms/step - loss: 8.6489 - val_loss: 9.2112\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 9.20296\n",
      "Epoch 177/200\n",
      "600/600 [==============================] - 65s 108ms/step - loss: 8.7317 - val_loss: 9.1869\n",
      "\n",
      "Epoch 00177: val_loss improved from 9.20296 to 9.18693, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 178/200\n",
      "600/600 [==============================] - 69s 115ms/step - loss: 8.6370 - val_loss: 9.2174\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 9.18693\n",
      "Epoch 179/200\n",
      "600/600 [==============================] - 68s 113ms/step - loss: 8.6304 - val_loss: 9.1718\n",
      "\n",
      "Epoch 00179: val_loss improved from 9.18693 to 9.17180, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 180/200\n",
      "600/600 [==============================] - 60s 100ms/step - loss: 8.6477 - val_loss: 9.1838\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 9.17180\n",
      "Epoch 181/200\n",
      "600/600 [==============================] - 64s 106ms/step - loss: 8.6076 - val_loss: 9.1799\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 9.17180\n",
      "Epoch 182/200\n",
      "600/600 [==============================] - 67s 111ms/step - loss: 8.6161 - val_loss: 9.1486\n",
      "\n",
      "Epoch 00182: val_loss improved from 9.17180 to 9.14856, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 183/200\n",
      "600/600 [==============================] - 58s 97ms/step - loss: 8.6074 - val_loss: 9.1568\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 9.14856\n",
      "Epoch 184/200\n",
      "600/600 [==============================] - 58s 96ms/step - loss: 8.5640 - val_loss: 9.2122\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 9.14856\n",
      "Epoch 185/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 8.6223 - val_loss: 9.1376\n",
      "\n",
      "Epoch 00185: val_loss improved from 9.14856 to 9.13758, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 186/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 8.5692 - val_loss: 9.1559\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 9.13758\n",
      "Epoch 187/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 8.6113 - val_loss: 9.1368\n",
      "\n",
      "Epoch 00187: val_loss improved from 9.13758 to 9.13681, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 188/200\n",
      "600/600 [==============================] - 57s 96ms/step - loss: 8.5681 - val_loss: 9.1497\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 9.13681\n",
      "Epoch 189/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 8.5535 - val_loss: 9.1043\n",
      "\n",
      "Epoch 00189: val_loss improved from 9.13681 to 9.10431, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 190/200\n",
      "600/600 [==============================] - 57s 95ms/step - loss: 8.5475 - val_loss: 9.1211\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 9.10431\n",
      "Epoch 191/200\n",
      "600/600 [==============================] - 56s 94ms/step - loss: 8.5387 - val_loss: 9.1009\n",
      "\n",
      "Epoch 00191: val_loss improved from 9.10431 to 9.10086, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 192/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 8.5373 - val_loss: 9.1295\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 9.10086\n",
      "Epoch 193/200\n",
      "600/600 [==============================] - 54s 90ms/step - loss: 8.5546 - val_loss: 9.1037\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 9.10086\n",
      "Epoch 194/200\n",
      "600/600 [==============================] - 56s 94ms/step - loss: 8.5277 - val_loss: 9.1057\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 9.10086\n",
      "Epoch 195/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 8.5110 - val_loss: 9.2097\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 9.10086\n",
      "Epoch 196/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 8.5682 - val_loss: 9.1157\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 9.10086\n",
      "Epoch 197/200\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 8.5201 - val_loss: 9.0646\n",
      "\n",
      "Epoch 00197: val_loss improved from 9.10086 to 9.06456, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 198/200\n",
      "600/600 [==============================] - 56s 93ms/step - loss: 8.4982 - val_loss: 9.1794\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 9.06456\n",
      "Epoch 199/200\n",
      "600/600 [==============================] - 54s 91ms/step - loss: 8.5092 - val_loss: 9.0603\n",
      "\n",
      "Epoch 00199: val_loss improved from 9.06456 to 9.06034, saving model to vgg16_eds_10292021_lr_7.h5\n",
      "Epoch 200/200\n",
      "600/600 [==============================] - 55s 91ms/step - loss: 8.4815 - val_loss: 9.0670\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 9.06034\n"
     ]
    }
   ],
   "source": [
    "eds_history_10292021_lr_7 = model_lr_7.fit(X_EDS_train,Y_EDS_train,validation_data=(X_EDS_test,Y_EDS_test),epochs=200, batch_size=16,callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_7.save(\"vgg16_modelfile_10292021_10sample_epo200_batch16.h5\")\n",
    "model_lr_7.save_weights('vgg16_weightsfile_10292021_10sample_epo200_batch16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "eds_history_10292021_df = pd.DataFrame(eds_history_10292021_lr_7.history) \n",
    "eds_history_10292021_df.to_excel('saved_training_histroy_10292021.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_10292021 = model_lr_7.predict(X_EDS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, \"Ground truth Young's modulus \\nfrom indenation experiments, GPa\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots(figsize=(5,5))\n",
    "ax.scatter(Y_EDS_test,pred_10292021)\n",
    "ax.set_xlim([10,30])\n",
    "ax.set_ylim([10,30])\n",
    "ax.set_ylabel(\"Predicted Young's modulus, GPa\")\n",
    "ax.set_xlabel(\"Ground truth Young's modulus \\nfrom indenation experiments, GPa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
